# セキュリティ監視に必要な3つの機能

- 用語定義
    - `ログ`: セキュリティに関連する事象（イベント）を記録したデータ全般
        - これ自身を「イベント」と呼ぶこともある
        - 基本的には1つの事象に対する記録が1つのログ、ということにしておきたい
        - 一般化して説明しようとするとかなり難しいというか抽象化されすぎてしまうので、ここではあまり突き詰めない
    - `アラート`: セキュリティ侵害が発生している可能性がある、とラベル付けされたログ（複数の場合もある）
        - 誤検知や影響のないイベントを検出したものも含む
        - 検出方法（ラベルの付け方）については後述
        - 同じ概念だが "Incident", "Detection", "Finding", "Event of Interest", "Offense" など、製品や規格によって呼び方はバラバラ
        - この文書では「アラート」で統一する
    - `セキュリティ監視`: ログを集め、その中からアラートを見つけ、そのアラートは現実の被害や影響がある事象を捉えていたのかを調査し、もし影響があったら対応に必要な情報を収集する、という業務
- ほぼ定義のままだが、セキュリティ監視に必要な要件はアラートの検出・調査・管理

## アラートの検出

- アラートの検出方法は概ね以下の4通りある
    - 監視装置からあがってくるアラート
        - セキュリティ監視のためのデバイス、あるいはその機能を併せ持つデバイスが「アラートです」と言って送ってくるアラート
        - NGFW (Next Generation Firewall)、IDS (Intrusion Detection System)、WAF (Web Application Firewall) アンチウィルスソフトなど、そもそもアラートを見つける機能を持っているデバイス（もちろんソフトウェアベースのものも含む）
        - 監視デバイス側で判定してくれるので楽だが、ロジックの調整はする必要がある
            - 過剰にアラートを検出している場合はアラートを集約した先でも調整できる
            - 感度が低いという場合はデバイス側を調整するしかない
    - メトリクス型のアラート
        - 特定の種類のログが一定時間内にN回発生したら発火するタイプのアラート
        - 例：「ログイン失敗が10分以内に10回発生するのを検知」
        - 監視デバイス側で同等のことをやってくれる場合と、ログを集約した先でそういったロジックを組む場合がある
        - インフラ監視のプロダクト・ツールで実現できる場合もある（nagios、zabbixなど）
            - ただし、回数カウントのためのキーが爆発的に多い場合があるので注意が必要
            - 例えばアクセスしてくるIPアドレスがキーだと1,000〜1,000,000というようなオーダーになる
        - 事前にしきい値を決めておく
    - ルールベースのアラート
        - ログに出現する値をなどについて事前に決めた条件に合致した場合発火するアラート
        - 単一のログをみる場合
            - 組織や監視対象によってアラートとして扱うかどうかが微妙な事象に対して、組織で決めたポリシーに基づいて発報するもの
            - 例えば、完成したててまだ不安定なWebサービスだとInternal Server Error（HTTPの応答コード500）はセキュリティ監視の観点からはあまり重要ではないかもしれないが、安定して動作しているWebサービスだと攻撃を受けてなんらかの影響がでた可能性が考えられる、など（ちょっといい例えではないかもしれない）
        - 複数のログを組み合わせてみる場合
            - 例「ポートスキャンの発生を示すログのあとにExploitコードの送信を示すログが出現したら攻撃と判定する」
        - SIEM (Security Informaion & Event Manager) が得意とする機能（詳しくは後述）
        - 基本的にはルールを運用するメンバーが管理する必要がある
            - ビジネスロジックに関連するものだとルールの管理にはなおさらドメイン知識が必要になる
                - サービス上での不正を発見するために必要
                - 例：不正送金や不正取引のようなサービス上問題になる利用方法など
            - また異なる監視装置・製品・サービス間のログをつなげるのも大変
            - ログの種類を抽象化し、汎用的なルールだけ管理するというアプローチをしている某SIEM製品があるが、ログの抽象化が残念で厳しい様子だった
        - ちゃんとやるならしっかり自組織内でルールを管理・運用していく心構えが必要
    - アナリスト（人間）がログから検出するアラート
        - アラートとは直接関係ないログ（たいだい大量）からアナリストが知識・経験・直感をもとに見つけ出したアラート
            - システムへのセキュリティ侵害だと、例えば現実にはまだシステムに取り込まれていないようなIoC (Indicator of Compromise) 情報をログから検索したりした結果の場合が多い
            - あるいはセキュリティ監視とは関係ないところから不審な事象が発見された場合に、実際に問題がなかったか調査するというようなケース
        - でもたまに本気で人間が（一部のカテゴリだけだったりするけど）目視でログを見て分析しているサービスもあったりする
        - IoCを使うものはともかく人間がログを日々見るのは結構大変（神経が削れる）なので、定常運用はあまりオススメできない
            - なのでロジック化した上でルールによって検知するようにしていくのが良い
    - 一応、他にも異常検知のカテゴリはあるが、…まあ頑張りたい人は頑張ってみてくれ、という気持ち
        - アラートに直接関係しないようなログはセキュリティ以外の要素に影響されやすい
            - 利用している・提供しているサービスそのものの異常ないしトラブル
            - 外的要因。極端な例で言えばYahoo砲で、内部の状況に関係なくいつもと挙動が変わったりするケース
- これらのアラートの検出を管理・調整できる運用が必要
    - アラートの検出結果の善し悪しは必ず組織によって異なるので画一的な検出ルールで運用するのは非常に厳しい
        - 事業会社ならやっているビジネスが違う
        - 組織ごとの温度感の違い・体制
        - 「防止」の対策をどれくらい＆どのように導入・運用しているのかにも影響してくる
    - なので導入前だけでなく継続的にアラート検出のロジックを修正してく必要がある
        - どちらかというと最終的にアラートとして管理されるフェイズに届く前にフィルタするような仕組みのほうが便利
            - ルールを一箇所にまとめて管理できるから
            - 監視装置毎の条件の設定方法などを（あまり）覚える必要がなく手間が省けるから
            - ただしどちらにしてもログに含まれるデータ構造などは把握してく必要がある
    - さらに出力も統一されているのが望ましい
        - 各監視装置内でアラートを管理する機能を持っているものもあるが、そこで管理しようとすると監視装置の数だけ操作やデータのあり方を覚える必要が出てくる
            - 教育などの負担増
            - いちいち監視装置にログインし直したりするのはだいぶ手間
        - また、アラートの情報を横断的に見れなくなる
        - 統一された形式で管理できるのであれば、監視装置などの特性について把握しておく必要はあるものの、だいぶ負担が減る


##  アラートの調査

- 端的に言い換えると「アラートに関連するログを検索できる」機能のこと
- 検出されたアラートは（定義上というのもあるが現実的に）自分たちが守るべき環境・資産に対して影響を及ぼすかどうかがわからない場合がほとんど
    - 誤検知：いわゆるFalse Positve
        - 本来セキュリティ侵害とは全く関係ない事象をアラートとして捉えてしまうようなケース
        - 例えば、特定の脆弱性に対する攻撃の通信を検出するためにその攻撃に発生する特徴的な文字列を検出ルールに書いていたら、その脆弱性を解説するページを閲覧した通信が引っかかってしまった、という事例
    - 過検知：過剰検知とも呼ぶ。本物の攻撃がアラートとして検出されたが、実際には影響がなかったようなケース
        - 例えば、Windowsサーバに対する攻撃の通信を検知したが、宛先のサーバはLinuxでした、という事例
        - 誤検知の場合はルールの調整をして精度を高めればいいが、過検知はその監視装置が見えている側面や検出エンジンのロジックだけでは不十分のために発生するものであり、本質的に必ず発生しうる
- そのため検出されたアラートが影響を及ぼす可能性があるかどうかを調べる必要がある
    - もちろんアラートの影響方法の調査方法はログを調べるだけではない
    - 直接、問題がありそうな箇所（PC、サーバ、ネットワークなど）を調べるという手ももちろんある
    - ただしどうしてもインタラクティブに調査しなければならないことというのは割と少ない
    - コンピュータ上を調べるにしてもネットワークを調べるにしても、だいたいは「ポイントを絞ってなんらかの情報を取得する」という行為になることが多い
        - ネットワークに流れるトラフィックの内容を調べる
        - サーバ上で動作するプロセスを調べる
        - 最近生成されたファイルを調べる
    - そういったログはOS標準機能やOSSなどでもかなり広範に取得することができる
    - そして、情報の取得は人間が活動している "まさにその瞬間" しかできず、過去の情報を取得するのは困難な場合がある
    - なので調査のために必要な情報はかなりの部分が継続的かつ多様なログの取得によってカバーできる
        - ただし先述の通り直接でなければ調査が難しいものもある。物理メディアを接収しての調査など
- 「快適に」ログが検索できることが重要
    - 詳しくは後述
    - 快適に検索できれば調査のための集中力を途切れさせにくくなる
    - 単純に時間が短縮できるというメリットも大きい
- 人間がやる調査作業の省力化も重要な機能
    - 調査の作業はだいたい定型的で誰がやっても同じ
    - 「このアラートだったらこの情報を集める」というような定型化できる部分はなるべくプログラムにやらせる
    - 人間は定型的ではない情報の収集や、集まった情報からどのように判断するか、という部分に注力する
    - 「アラートに関連しそうな情報を（AI的ななにかで）自動的に集めてくる」というプロダクトやサービスもあるが、個人的な経験則ではだいたい過剰に集めがちでノイズが多くなり重要な情報が逆に埋もれてしまいがち
    - 本当に必要な情報が何かはなるべく人間がちゃんと決めるべき

## アラートの管理

- アラートが検出されたら対応しなければいけない
- アラート対応状況の記録・共有が「管理」
- 複数人で対応する場合、どこまで作業が進んでいるかなどを共有する必要がある
    - 一度調べたことを何度も調べたりするのは無駄
    - 特に役割分担がされている場合だと
- 一人で作業する場合でも、記録を残しておくのは有益
    - あとからチームを作る場合に、あとから参加した人が普段どのように対応しているかというのを後追いできる
    - 普段どのくらいアラートに対応しているか、などの計測にも役立つ
    - アラートの流量を調整するための指標にもなる
- 記録にはチケット管理システムが適している
    - テキストチャット、メールなどによる対応だと1つのアラートに対する情報が散らばっていまいあとからまとめるのが困難になりがち
    - 1アラートに対して1チケットで対応する
    - 場合によっては複数アラートを1チケットにまとめる
        - 例えば同じホストから複数のアラートが同時期にあがってきた場合、集約したほうが見通しがいい
        - どのキーで集約するのかはアラートの種類・性質によって異なるため一概には言えない
